import io
import os
import json
import glob
from typing import List, Optional, Tuple

import numpy as np
import streamlit as st
from PIL import Image

# TensorFlow / Keras (kurulu deÄŸilse uygulama Ã§Ã¶kmemesi iÃ§in korumalÄ± import)
try:
    import tensorflow as tf
    TF_AVAILABLE = True
    TF_IMPORT_ERR = None
except Exception as _e:
    TF_AVAILABLE = False
    TF_IMPORT_ERR = str(_e)

st.set_page_config(page_title="CIFAR-100 Keras (H5) Demo", page_icon="ğŸ§ª", layout="centered")
st.title("ğŸ§ª CIFAR-100 â€“ Keras .h5 Model CanlÄ± Demo")

# -------------------------------------------------------------
# CIFAR-100 fine label names (index order 0..99) â€“ yedek olarak kullanÄ±lÄ±r
# -------------------------------------------------------------
CIFAR100_FINE = [
    "apple","aquarium_fish","baby","bear","beaver","bed","bee","beetle","bicycle","bottle",
    "bowl","boy","bridge","bus","butterfly","camel","can","castle","caterpillar","cattle",
    "chair","chimpanzee","clock","cloud","cockroach","couch","crab","crocodile","cup","dinosaur",
    "dolphin","elephant","flatfish","forest","fox","girl","hamster","house","kangaroo","keyboard",
    "lamp","lawn_mower","leopard","lion","lizard","lobster","man","maple","motorcycle","mountain",
    "mouse","mushroom","oak","orange","orchid","otter","palm","pear","pickup_truck","pine",
    "plain","plate","poppy","porcupine","possum","rabbit","raccoon","ray","road","rocket",
    "rose","sea","seal","shark","shrew","skunk","skyscraper","snail","snake","spider","squirrel",
    "streetcar","sunflower","sweet_pepper","table","tank","telephone","television","tiger","tractor","train",
    "trout","tulip","turtle","wardrobe","whale","willow","wolf","woman","worm"
]

# -------------------------------------------------------------
# Kaynak seÃ§enekleri: Local / Hugging Face / Direct URL
# -------------------------------------------------------------
import pathlib
MODELS_DIR = pathlib.Path(os.environ.get("MODELS_DIR", "models"))
MODELS_DIR.mkdir(parents=True, exist_ok=True)
FOUND_MODELS = sorted([p.name for p in MODELS_DIR.glob("*.h5")] + [p.name for p in MODELS_DIR.glob("*.keras")])

with st.sidebar:
    st.header("ğŸ“¦ Model KaynaÄŸÄ±")
    source = st.radio("Model kaynaÄŸÄ±", ["Local (.h5)", "Hugging Face Hub", "Direct URL"], index=0)

    selected_model_path = ""
    if source == "Local (.h5)":
        if not FOUND_MODELS:
            st.info("models/ klasÃ¶rÃ¼ne .h5/.keras dosyalarÄ± koyun.")
        else:
            selected_name = st.selectbox("Yerel model", FOUND_MODELS)
            selected_model_path = str(MODELS_DIR / selected_name)

    elif source == "Hugging Face Hub":
        st.caption("Ã–rn. repo: your-username/cifar100-model, filename: model.h5")
        hf_repo = st.text_input("HF repo id", value="")
        hf_filename = st.text_input("Dosya adÄ±", value="model.h5")
        hf_revision = st.text_input("Revizyon/branch (opsiyonel)", value="")
        if st.button("ğŸ“¥ Hugging Face'ten indir"):
            try:
                from huggingface_hub import hf_hub_download
                path = hf_hub_download(repo_id=hf_repo, filename=hf_filename, revision=(hf_revision or None), local_dir=str(MODELS_DIR))
                st.success(f"Ä°ndirildi: {path}")
                selected_model_path = path
            except Exception as e:
                st.error(f"HF indirme hatasÄ±: {e}")

    elif source == "Direct URL":
        url = st.text_input("Model URL (.h5/.keras)", value="")
        url_name = st.text_input("Kaydetme adÄ±", value="model_from_url.h5")
        if st.button("ğŸ“¥ URL'den indir"):
            try:
                import requests
                dest = MODELS_DIR / url_name
                r = requests.get(url, timeout=60)
                r.raise_for_status()
                dest.write_bytes(r.content)
                st.success(f"Ä°ndirildi: {dest}")
                selected_model_path = str(dest)
            except Exception as e:
                st.error(f"URL indirme hatasÄ±: {e}")

    topk = st.number_input("Top-K", min_value=1, max_value=10, value=5, step=1)

    with st.expander("GeliÅŸmiÅŸ (opsiyonel)"):
        manual_size = st.number_input("Zorla giriÅŸ boyutu (0 = otomatik)", min_value=0, max_value=1024, value=0, step=8)
        force_softmax = st.checkbox("Ã‡Ä±kÄ±ÅŸa softmax uygula (zorla)", value=False,
                                    help="Model logit dÃ¶ndÃ¼rÃ¼yorsa aktif edin.")
        keep_aspect = st.checkbox("En-boy oranÄ±nÄ± koru (pad)", value=False)

# -------------------------------------------------------------
# YardÄ±mcÄ±lar
# -------------------------------------------------------------
@st.cache_resource(show_spinner=False)
def load_keras_model(path: str):
    if not path:
        raise FileNotFoundError("Model yolu boÅŸ.")
    model = tf.keras.models.load_model(path, compile=False)
    return model


def infer_input_size(model) -> int:
    """Modelin giriÅŸ boyutunu (kare) otomatik Ã§Ä±kar."""
    shape = model.input_shape
    # Ã‡oklu input ise ilkini al
    if isinstance(shape, list):
        shape = shape[0]
    # (None, H, W, C) bekleriz (channels_last)
    try:
        h, w = int(shape[1]), int(shape[2])
        if h > 0 and w > 0:
            return h if h == w else max(h, w)
    except Exception:
        pass
    # VarsayÄ±lan: 32 (CIFAR)
    return 32


def find_labels_for_model(model_path: str) -> List[str]:
    """AynÄ± isimli labels.json varsa onu kullan, yoksa CIFAR-100 fine."""
    stem = os.path.splitext(model_path)[0]
    for candidate in [stem + ".labels.json", stem + "_labels.json", stem + ".json", os.path.join(os.path.dirname(model_path), "labels.json")]:
        if os.path.exists(candidate):
            try:
                with open(candidate, "r", encoding="utf-8") as f:
                    labels = json.load(f)
                if isinstance(labels, dict):
                    labels = [labels[str(i)] for i in range(len(labels))]
                if isinstance(labels, list) and len(labels) > 0:
                    return labels
            except Exception:
                pass
    return CIFAR100_FINE


def letterbox(img: Image.Image, size: int) -> Image.Image:
    """En-boy oranÄ±nÄ± koruyarak pad'li kare resim oluÅŸturur."""
    w, h = img.size
    scale = min(size / w, size / h)
    nw, nh = int(w * scale), int(h * scale)
    resized = img.resize((nw, nh))
    canvas = Image.new("RGB", (size, size), (0, 0, 0))
    canvas.paste(resized, ((size - nw) // 2, (size - nh) // 2))
    return canvas


def preprocess(pil: Image.Image, size: int, keep_ratio: bool) -> tf.Tensor:
    if keep_ratio:
        pil = letterbox(pil.convert("RGB"), size)
    else:
        pil = pil.convert("RGB").resize((size, size))
    arr = tf.keras.preprocessing.image.img_to_array(pil)
    # Otomatik Ã¶lÃ§ekleme: EÄŸer modelde Rescaling katmanÄ± varsa ona bÄ±rakÄ±rÄ±z.
    # Yoksa 0-1 aralÄ±ÄŸÄ±na Ã¶lÃ§ekleriz.
    arr = arr / 255.0
    return tf.expand_dims(arr, 0)  # (1, H, W, C)


def model_has_softmax(model) -> bool:
    try:
        last = model.layers[-1]
        act = getattr(last, "activation", None)
        if act is None:
            return False
        return act.__name__ == "softmax"
    except Exception:
        return False


def to_probabilities(model, preds: np.ndarray) -> np.ndarray:
    if preds.ndim == 1:
        preds = preds[None, :]
    if force_softmax or not model_has_softmax(model):
        preds = tf.nn.softmax(preds, axis=1).numpy()
    return preds


def topk_from_probs(probs: np.ndarray, k: int) -> Tuple[List[int], List[float]]:
    k = int(min(k, probs.shape[1]))
    idxs = np.argsort(-probs, axis=1)[0][:k].tolist()
    vals = probs[0, idxs].astype(float).tolist()
    return idxs, vals

# -------------------------------------------------------------
# Ana akÄ±ÅŸ â€“ resim yÃ¼kleme ALANI ANA SAYFADA!
# -------------------------------------------------------------
uploaded = st.file_uploader("Bir gÃ¶rÃ¼ntÃ¼ yÃ¼kleyin", type=["png","jpg","jpeg","bmp","webp"], accept_multiple_files=False)

if not selected_model_path:
    st.warning("Sol taraftan bir model seÃ§in veya tam yol girin.")
    st.stop()

if not TF_AVAILABLE:
    st.error("TensorFlow yÃ¼klÃ¼ deÄŸil. AÅŸaÄŸÄ±daki talimatlarla kurun ve tekrar deneyin.

`requirements.txt` iÃ§eriÄŸi Ã¶rneÄŸi:

```
streamlit
pillow
tensorflow==2.15.0.post1
```

`runtime.txt` (Streamlit Cloud iÃ§in Python sÃ¼rÃ¼mÃ¼ sabitleme):

````
3.10
````

> Alternatif: `tensorflow-cpu==2.15.0.post1` de kullanÄ±labilir.

Hata: " + (TF_IMPORT_ERR or "unknown"))
    st.stop()

try:
    model = load_keras_model(selected_model_path)
except Exception as e:
    st.error(f"Model yÃ¼klenemedi: {e}")
    st.stop()

labels = find_labels_for_model(selected_model_path)

# GiriÅŸ boyutunu otomatik belirle (isteÄŸe baÄŸlÄ± manuel override)
auto_size = infer_input_size(model)
INPUT_SIZE = manual_size if manual_size > 0 else auto_size
st.caption(f"GiriÅŸ boyutu: {INPUT_SIZE}px (auto)")

if uploaded is None:
    st.info("ğŸ‘† Bir gÃ¶rÃ¼ntÃ¼ seÃ§tiÄŸinizde tahmin yapÄ±lacaktÄ±r.")
    st.stop()

# GÃ¶rseli gÃ¶ster
img = Image.open(io.BytesIO(uploaded.read()))
st.image(img, caption="YÃ¼klenen GÃ¶rsel", use_column_width=True)

# Ã–n-iÅŸleme ve tahmin
x = preprocess(img, INPUT_SIZE, keep_aspect)
with st.spinner("Tahmin ediliyor..."):
    preds = model.predict(x, verbose=0)
probs = to_probabilities(model, preds)

# Top-K sonuÃ§lar
idxs, vals = topk_from_probs(probs, topk)

st.subheader(f"ğŸ”® Tahminler (Top-{topk})")
for r, (i, p) in enumerate(zip(idxs, vals), start=1):
    name = labels[i] if 0 <= i < len(labels) else f"class_{i}"
    st.write(f"**{r}. {name}** â€” {p:.3f}")

st.success("TamamlandÄ± âœ…")

st.markdown("---")
st.markdown(
    """
**KullanÄ±m:**
1. `models/` klasÃ¶rÃ¼ne `.h5` / `.keras` dosyalarÄ±nÄ±zÄ± koyun.
2. Gerekirse aynÄ± klasÃ¶re `labels.json` (veya `model.labels.json`) ekleyin; yoksa **CIFAR-100 fine** etiketleri kullanÄ±lÄ±r.
3. Uygulama giriÅŸ boyutunu **otomatik** algÄ±lar (model.input_shape). Ä°sterseniz GeliÅŸmiÅŸ bÃ¶lÃ¼mÃ¼nden override edebilirsiniz.
    """
)
